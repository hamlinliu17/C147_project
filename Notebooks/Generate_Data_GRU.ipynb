{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generate_Data_GRU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"y9W2o-wF040e"},"source":["#Generate Data for GRU\r\n","This is the code used to generate data from the GRU generators "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEAUQsWeOMoc","executionInfo":{"status":"ok","timestamp":1615443134191,"user_tz":480,"elapsed":17456,"user":{"displayName":"HAMLIN LIU","photoUrl":"","userId":"03736600407649495009"}},"outputId":"bf0d0040-51eb-47e1-9040-f349f124512c"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yF0tnBs2Pat7"},"source":["os.chdir('/content/drive/My Drive/c147_project/')\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import os\n","import time\n","from data import eegData\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","%load_ext autoreload\n","%autoreload 2\n","# get the device type of machine\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nr8e0bp8O3Ml"},"source":["# These are the generator coes \n","\n","class GRUGenerator(nn.Module):\n","  \"\"\"\n","  Generator that uses LSTM layer\n","  input is (batch, in_dim, seq)\n","  output is (batch, out_dim, seq)\n","  \"\"\"\n","  def __init__(self, input_dim, hidden_dim, output_dim=22, n_layers=1, bias=False):\n","    super(GRUGenerator, self).__init__()\n","    self.input_dim = input_dim\n","    self.out_dim = output_dim\n","    self.hidden_dim = hidden_dim\n","    self.gru = nn.GRU(input_dim, hidden_dim, num_layers=n_layers, bias=bias, batch_first=True)\n","\n","    self.linear = nn.Sequential(\n","        nn.Linear(hidden_dim, output_dim),\n","        nn.Tanh()\n","    )\n","\n","\n","  def forward(self, x):\n","    d1, d2, d3 = x.shape \n","    x_reshaped = x.view(d1, d3, d2)\n","    recurrent, _ = self.gru(x_reshaped)\n","    out = self.linear(recurrent.contiguous().view(d1 * d3, self.hidden_dim))\n","    return out.view(d1, self.out_dim, d3)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R1vKHrO2RKdZ"},"source":["# generate the noise as well as fake labels\n","num_trials = 1000\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kh5PxbwOSlf0"},"source":["labels_store = torch.randint(0, 4, (num_trials, 1))\n","labels = labels_store.repeat(1, 100).reshape(num_trials, 1, -1)\n","labels.shape\n","sd = torch.load('Models/GRU-CNN/Generator_5000.pth')\n","GRU_CNN= GRUGenerator(4, 44)\n","GRU_CNN.load_state_dict(sd)\n","GRU_CNN.eval()\n","noise = torch.rand((num_trials, GRU_CNN.input_dim - 1, 100))\n","noise = torch.cat([noise, labels], dim=1)\n","\n","\n","fake_data = GRU_CNN(noise)\n","\n","label_to_file = labels_store.numpy()\n","data_to_file = fake_data.detach().numpy()\n","\n","np.save('Models/Fake_Data/GRU-CNN_data.npy', data_to_file)\n","np.save('Models/Fake_Data/GRU-CNN_labels.npy', label_to_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVlugKc6btUj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615443202934,"user_tz":480,"elapsed":561,"user":{"displayName":"HAMLIN LIU","photoUrl":"","userId":"03736600407649495009"}},"outputId":"bece6ce1-2c2b-4824-8fbf-d24f35ef9298"},"source":["labels_store = torch.randint(0, 4, (num_trials, 1))\r\n","labels =labels_store.repeat(1, 100).reshape(num_trials, 1, -1)\r\n","labels.shape\r\n","\r\n","sd = torch.load('Models/GRU-LSTM/Generator_5000.pth')\r\n","GRU_LSTM= GRUGenerator(4, 44)\r\n","GRU_LSTM.load_state_dict(sd)\r\n","print(GRU_LSTM.eval())\r\n","noise = torch.rand((num_trials, GRU_LSTM.input_dim - 1, 100))\r\n","noise = torch.cat([noise, labels], dim=1)\r\n","noise.shape\r\n","\r\n","fake_data = GRU_CNN(noise)\r\n","\r\n","label_to_file = labels_store.numpy()\r\n","data_to_file = fake_data.detach().numpy()\r\n","\r\n","np.save('Models/Fake_Data/GRU-LSTM_data.npy', data_to_file)\r\n","np.save('Models/Fake_Data/GRU-LSTM_labels.npy', label_to_file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRUGenerator(\n","  (gru): GRU(4, 44, bias=False, batch_first=True)\n","  (linear): Sequential(\n","    (0): Linear(in_features=44, out_features=22, bias=True)\n","    (1): Tanh()\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EkKp6XtOuQL1"},"source":["model_test = torch.load('Models_backup/GRU-LSTM/Generator_5000.pth', map_location=device)\n","sd = model_test.state_dict()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ds_R_tJuejS"},"source":["model_real = GRUGenerator(4, 44)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hg9YprrEu1Em","executionInfo":{"status":"ok","timestamp":1615389750425,"user_tz":480,"elapsed":602,"user":{"displayName":"HAMLIN LIU","photoUrl":"","userId":"03736600407649495009"}},"outputId":"b2df719e-aaea-4d88-a308-a714e52e338a"},"source":["model_real.load_state_dict(sd)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"SVtEoFJMu3IJ"},"source":[""],"execution_count":null,"outputs":[]}]}